{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "scrape_daily.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.1"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pTCtQWA9iey"
      },
      "source": [
        "import requests\n",
        "import urllib\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import io\n",
        "import gzip\n",
        "import time\n",
        "import csv\n",
        "import os\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def scrape_daily(sym):\n",
        "    print(sym)\n",
        "    url = \"https://query1.finance.yahoo.com/v7/finance/download/\"+sym+\"?period1=1451692800&period2=1609545600&interval=1d&events=history&includeAdjustedClose=true\"\n",
        "    response = requests.get(url)\n",
        "    bytes_io = io.BytesIO(response.content)\n",
        "    df_daily = pd.read_csv(bytes_io, error_bad_lines = False)\n",
        "    df_daily.to_csv(sym + \"_daily.csv\")\n",
        "\n",
        "def scrape_monthly(sym):\n",
        "    print(sym)\n",
        "    url = \"https://finance.yahoo.com/quote/\" + sym + \"/history?period1=1451692800&period2=1609545600&interval=1mo&filter=history&frequency=1mo&includeAdjustedClose=true\"\n",
        "    response = requests.get(url)\n",
        "    bytes_io = io.BytesIO(response.content)\n",
        "    df_monthly = pd.read_csv(bytes_io, sep='\\t')\n",
        "    df_monthly.to_csv(sym + \"_monthly.csv\")\n",
        "\n",
        "def scrape_weekly(sym):\n",
        "    print(sym)\n",
        "    url = \"https://query1.finance.yahoo.com/v7/finance/download/\"+sym+\"?period1=1451692800&period2=1609545600&interval=1wk&events=history&includeAdjustedClose=true\"\n",
        "    response = requests.get(url)\n",
        "    bytes_io = io.BytesIO(response.content)\n",
        "    df_weekly = pd.read_csv(bytes_io, error_bad_lines=False)\n",
        "    df_weekly.to_csv(sym + \"_weekly.csv\")\n",
        "\n",
        "\n",
        "def scrape_monthly(sym):\n",
        "    print(sym)\n",
        "    url = \"https://query1.finance.yahoo.com/v7/finance/download/\"+sym+\"?period1=1451692800&period2=1609545600&interval=1mo&events=history&includeAdjustedClose=true\"\n",
        "    response = requests.get(url)\n",
        "    bytes_io = io.BytesIO(response.content)\n",
        "    df_monthly = pd.read_csv(bytes_io, error_bad_lines=False)\n",
        "    df_monthly.to_csv(sym + \"_monthly.csv\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "====== WebDriver manager ======\n",
            "Current google-chrome version is 91.0.4472\n",
            "Get LATEST driver version for 91.0.4472\n",
            "Driver [C:\\Users\\Chowdary\\.wdm\\drivers\\chromedriver\\win32\\91.0.4472.101\\chromedriver.exe] found in cache\n",
            "505\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import urllib\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import io\n",
        "import gzip\n",
        "import time\n",
        "import csv\n",
        "import os\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from multiprocessing import Pool\n",
        "import import_ipynb\n",
        "import pandas as pd\n",
        "from ipynb.fs.full.scrape_daily import scrape_daily\n",
        "\n",
        "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
        "url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
        "driver.get(url)\n",
        "\n",
        "symbols = list()\n",
        "symbols_GICC = dict()\n",
        "\n",
        "table = \"/html/body/div[3]/div[3]/div[5]/div[1]/table[1]\"\n",
        "table = driver.find_element_by_xpath(table)\n",
        "elements = table.find_elements_by_tag_name(\"tr\")[1:]\n",
        "\n",
        "for row in elements:\n",
        "    data = [data.text for data in row.find_elements_by_tag_name(\"td\")]\n",
        "    symbols.append(data[0])\n",
        "    symbols_GICC[data[0]] = data[3]\n",
        "\n",
        "print(len(symbols_GICC))\n",
        "    \n",
        "\n",
        "if __name__ == '__main__':\n",
        "    p = Pool(25)\n",
        "    df_daily_list = p.map(scrape_daily, symbols)\n",
        "    p.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "====== WebDriver manager ======\n",
            "Current google-chrome version is 91.0.4472\n",
            "Get LATEST driver version for 91.0.4472\n",
            "Driver [C:\\Users\\Chowdary\\.wdm\\drivers\\chromedriver\\win32\\91.0.4472.101\\chromedriver.exe] found in cache\n",
            "505\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import requests\n",
        "import urllib\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import io\n",
        "import gzip\n",
        "import time\n",
        "import csv\n",
        "import os\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from multiprocessing import Pool\n",
        "import import_ipynb\n",
        "import pandas as pd\n",
        "from ipynb.fs.full.scrape_daily import scrape_monthly\n",
        "\n",
        "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
        "url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
        "driver.get(url)\n",
        "\n",
        "symbols = list()\n",
        "symbols_GICC = dict()\n",
        "\n",
        "\n",
        "table = \"/html/body/div[3]/div[3]/div[5]/div[1]/table[1]\"\n",
        "table = driver.find_element_by_xpath(table)\n",
        "elements = table.find_elements_by_tag_name(\"tr\")[1:]\n",
        "    \n",
        "for row in elements:\n",
        "    data = [data.text for data in row.find_elements_by_tag_name(\"td\")]\n",
        "    symbols.append(data[0])\n",
        "    symbols_GICC[data[0]] = data[3]\n",
        "\n",
        "print(len(symbols_GICC))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    p = Pool(20)\n",
        "    p.map(scrape_monthly, symbols)\n",
        "    p.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "====== WebDriver manager ======\n",
            "Current google-chrome version is 91.0.4472\n",
            "Get LATEST driver version for 91.0.4472\n",
            "Driver [C:\\Users\\Chowdary\\.wdm\\drivers\\chromedriver\\win32\\91.0.4472.101\\chromedriver.exe] found in cache\n",
            "\n",
            "\n",
            "====== WebDriver manager ======\n",
            "Current google-chrome version is 91.0.4472\n",
            "Get LATEST driver version for 91.0.4472\n",
            "Driver [C:\\Users\\Chowdary\\.wdm\\drivers\\chromedriver\\win32\\91.0.4472.101\\chromedriver.exe] found in cache\n",
            "505\n",
            "\n",
            "\n",
            "====== WebDriver manager ======\n",
            "Current google-chrome version is 91.0.4472\n",
            "Get LATEST driver version for 91.0.4472\n",
            "Driver [C:\\Users\\Chowdary\\.wdm\\drivers\\chromedriver\\win32\\91.0.4472.101\\chromedriver.exe] found in cache\n",
            "505\n",
            "\n",
            "\n",
            "====== WebDriver manager ======\n",
            "Current google-chrome version is 91.0.4472\n",
            "Get LATEST driver version for 91.0.4472\n",
            "505\n",
            "Driver [C:\\Users\\Chowdary\\.wdm\\drivers\\chromedriver\\win32\\91.0.4472.101\\chromedriver.exe] found in cache\n",
            "505\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import urllib\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import io\n",
        "import gzip\n",
        "import time\n",
        "import csv\n",
        "import os\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from multiprocessing import Pool\n",
        "import import_ipynb\n",
        "import pandas as pd\n",
        "from ipynb.fs.full.scrape_daily import scrape_weekly\n",
        "\n",
        "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
        "url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
        "driver.get(url)\n",
        "\n",
        "symbols = list()\n",
        "symbols_GICC = dict()\n",
        "\n",
        "table = \"/html/body/div[3]/div[3]/div[5]/div[1]/table[1]\"\n",
        "table = driver.find_element_by_xpath(table)\n",
        "elements = table.find_elements_by_tag_name(\"tr\")[1:]\n",
        "\n",
        "for row in elements:\n",
        "    data = [data.text for data in row.find_elements_by_tag_name(\"td\")]\n",
        "    symbols.append(data[0])\n",
        "    symbols_GICC[data[0]] = data[3]\n",
        "\n",
        "print(len(symbols_GICC))\n",
        "    \n",
        "\n",
        "if __name__ == '__main__':\n",
        "    p = Pool(5)\n",
        "    df_daily_list = p.map(scrape_weekly, symbols)\n",
        "    p.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}